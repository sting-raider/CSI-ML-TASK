{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:28:24.931978Z",
     "start_time": "2025-03-26T01:28:24.925953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ],
   "id": "401a055eaea4f2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:28:25.890377Z",
     "start_time": "2025-03-26T01:28:25.883864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_and_preprocess_image(img_path, img_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Load an image, convert to grayscale, resize, apply Gaussian blur,\n",
    "    and normalize pixel values to [0,1].\n",
    "    \"\"\"\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def extract_features(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if image is None:\n",
    "        print(f\"Warning: Unable to load image {image_path}\")\n",
    "        return None  # Skip this image\n",
    "    \n",
    "    image = cv2.resize(image, (128, 128))  # Resize for consistency\n",
    "    \n",
    "    # HOG Feature Extraction\n",
    "    hog_features, _ = hog(image, pixels_per_cell=(16, 16), cells_per_block=(2, 2), visualize=True)\n",
    "    \n",
    "    # LBP Feature Extraction\n",
    "    lbp = local_binary_pattern(image, P=24, R=3, method=\"uniform\")\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(27), density=True)\n",
    "    \n",
    "    return np.hstack((hog_features, lbp_hist))\n",
    "\n",
    "\n",
    "def load_dataset(real_folder, fake_folder):\n",
    "    X, y = [], []\n",
    "    \n",
    "    for file in os.listdir(real_folder):\n",
    "        if file.lower() == \"thumbs.db\":\n",
    "            continue\n",
    "        img_path = os.path.join(real_folder, file)\n",
    "        features = extract_features(img_path)\n",
    "        if features is not None:\n",
    "            X.append(features)\n",
    "            y.append(1)\n",
    "    \n",
    "    for file in os.listdir(fake_folder):\n",
    "        if file.lower() == \"thumbs.db\":\n",
    "            continue\n",
    "        img_path = os.path.join(fake_folder, file)\n",
    "        features = extract_features(img_path)\n",
    "        if features is not None:\n",
    "            X.append(features)\n",
    "            y.append(0)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n"
   ],
   "id": "3dde484c977ab702",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T00:25:05.476590Z",
     "start_time": "2025-03-26T00:24:12.004444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "dataset_dir = './signature_dataset'\n",
    "real_path = os.path.join(dataset_dir, \"full_org\")\n",
    "fake_path = os.path.join(dataset_dir, \"full_forg\")\n",
    "X, y = load_dataset(real_path, fake_path)\n",
    "\n",
    "# Split dataset (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train an SVM classifier (using RBF kernel)\n",
    "clf = SVC(kernel='rbf', probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"=== CLASSIFICATION REPORT ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"=== CONFUSION MATRIX ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save the model for later use\n",
    "joblib.dump(clf, \"svm_signature_classifier.pkl\")"
   ],
   "id": "8065521d9ade0e47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CLASSIFICATION REPORT ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       264\n",
      "           1       0.98      0.99      0.98       264\n",
      "\n",
      "    accuracy                           0.98       528\n",
      "   macro avg       0.98      0.98      0.98       528\n",
      "weighted avg       0.98      0.98      0.98       528\n",
      "\n",
      "=== CONFUSION MATRIX ===\n",
      "[[258   6]\n",
      " [  3 261]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_signature_classifier.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:21:13.960094Z",
     "start_time": "2025-03-26T01:21:13.952314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super(ContentLoss, self).__init__()\n",
    "        self.target = target.detach()\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.loss_value = self.loss(x, self.target)\n",
    "        return x\n",
    "\n",
    "class StyleLoss(nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.target = target.detach().to(device)\n",
    "        self.loss = nn.MSELoss().to(device)\n",
    "\n",
    "    @staticmethod\n",
    "    def gram_matrix(x):\n",
    "        _, c, h, w = x.size()\n",
    "        features = x.view(c, h * w)\n",
    "        return torch.mm(features, features.t()) / (c * h * w)\n",
    "\n",
    "    def forward(self, x):\n",
    "        G = self.gram_matrix(x)\n",
    "        self.loss_value = self.loss(G, self.target)\n",
    "        return x\n",
    "\n",
    "def get_style_model_and_losses(cnn, normalization_mean, normalization_std, style_img, content_img):\n",
    "    normalization = nn.Sequential(\n",
    "        transforms.Normalize(normalization_mean, normalization_std)\n",
    "    ).to(device)\n",
    "    style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "    content_layers = ['conv_4']\n",
    "\n",
    "    model = nn.Sequential(normalization)\n",
    "    content_losses = []\n",
    "    style_losses = []\n",
    "\n",
    "    i = 0\n",
    "    for layer in cnn.children():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            i += 1\n",
    "            name = f\"conv_{i}\"\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            name = f\"relu_{i}\"\n",
    "            layer = nn.ReLU(inplace=False)\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            name = f\"pool_{i}\"\n",
    "        elif isinstance(layer, nn.BatchNorm2d):\n",
    "            name = f\"bn_{i}\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        model.add_module(name, layer)\n",
    "\n",
    "        if name in content_layers:\n",
    "            target = model(content_img).detach()\n",
    "            content_loss = ContentLoss(target)\n",
    "            model.add_module(f\"content_loss_{i}\", content_loss)\n",
    "            content_losses.append(content_loss)\n",
    "\n",
    "        if name in style_layers:\n",
    "            target_feature = model(style_img).detach()\n",
    "            target_gram = StyleLoss.gram_matrix(target_feature)\n",
    "            style_loss = StyleLoss(target_gram)\n",
    "            model.add_module(f\"style_loss_{i}\", style_loss)\n",
    "            style_losses.append(style_loss)\n",
    "\n",
    "    return model, style_losses, content_losses\n"
   ],
   "id": "c6e8769243168093",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:21:14.542561Z",
     "start_time": "2025-03-26T01:21:14.533454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_style_transfer(\n",
    "    cnn,\n",
    "    normalization_mean,\n",
    "    normalization_std,\n",
    "    content_img,\n",
    "    style_img,\n",
    "    input_img,\n",
    "    num_steps=300,\n",
    "    style_weight=1e6,\n",
    "    content_weight=1,\n",
    "    device=None  # Add device parameter\n",
    "):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    writer = SummaryWriter('./runs/style_transfer')\n",
    "    \n",
    "    # Explicit device placement\n",
    "    style_img = style_img.to(device)\n",
    "    content_img = content_img.to(device)\n",
    "    input_img = input_img.to(device)\n",
    "    normalization_mean = normalization_mean.to(device)\n",
    "    normalization_std = normalization_std.to(device)\n",
    "\n",
    "    model, style_losses, content_losses = get_style_model_and_losses(\n",
    "        cnn, normalization_mean, normalization_std, style_img, content_img\n",
    "    )\n",
    "\n",
    "    input_img = input_img.requires_grad_()\n",
    "    optimizer = optim.LBFGS([input_img])\n",
    "\n",
    "    run = [0]\n",
    "    \n",
    "    while run[0] <= num_steps:\n",
    "        def closure():\n",
    "            with torch.no_grad():\n",
    "                input_img.clamp_(0, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model(input_img)\n",
    "            \n",
    "            style_score = torch.tensor(0., device=device)\n",
    "            content_score = torch.tensor(0., device=device)\n",
    "            \n",
    "            if style_losses:\n",
    "                style_score = sum(sl.loss_value for sl in style_losses)\n",
    "            if content_losses:\n",
    "                content_score = sum(cl.loss_value for cl in content_losses)\n",
    "\n",
    "            total_loss = style_weight * style_score + content_weight * content_score\n",
    "            total_loss.backward()\n",
    "\n",
    "            if writer:\n",
    "                writer.add_scalar('Loss/Style', style_score.item(), run[0])\n",
    "                writer.add_scalar('Loss/Content', content_score.item(), run[0])\n",
    "                writer.add_scalar('Loss/Total', total_loss.item(), run[0])\n",
    "\n",
    "            run[0] += 1\n",
    "            return total_loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_img.clamp_(0, 1)\n",
    "    \n",
    "    if writer:\n",
    "        writer.close()\n",
    "    \n",
    "    return input_img\n",
    "\n",
    "def nst_signature_forgery(\n",
    "    content_dir, \n",
    "    style_dataset, \n",
    "    save_dir, \n",
    "    cnn, \n",
    "    normalization_mean, \n",
    "    normalization_std,\n",
    "    device,\n",
    "    imsize=128,\n",
    "    num_steps=300,\n",
    "    num_images=50,\n",
    "    style_weight=1e5,\n",
    "    content_weight=1\n",
    "):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    generated_forgeries = []\n",
    "    processed_count = 0\n",
    "    \n",
    "    # Get limited list of content images\n",
    "    content_files = [f for f in os.listdir(content_dir) if f.lower().endswith((\"jpg\", \"png\", \"jpeg\"))][:num_images]\n",
    "    \n",
    "    for content_file in content_files:\n",
    "        content_img_path = os.path.join(content_dir, content_file)\n",
    "        \n",
    "        try:\n",
    "            content_img = image_loader(content_img_path, device, imsize)\n",
    "            idx = random.randrange(len(style_dataset))\n",
    "            style_img, _ = style_dataset[idx]\n",
    "            style_img = style_img.unsqueeze(0).to(device, torch.float)\n",
    "            \n",
    "            input_img = content_img.clone() + torch.randn_like(content_img) * 0.1\n",
    "            \n",
    "            output = run_style_transfer(\n",
    "                cnn,\n",
    "                normalization_mean,\n",
    "                normalization_std,\n",
    "                content_img,\n",
    "                style_img,\n",
    "                input_img,\n",
    "                num_steps=num_steps,\n",
    "                style_weight=style_weight,\n",
    "                content_weight=content_weight,\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            output_path = os.path.join(save_dir, f\"forged_{content_file}\")\n",
    "            save_image(output, output_path)\n",
    "            \n",
    "            generated_forgeries.append(output_path)\n",
    "            processed_count += 1\n",
    "            print(f\"Generated {processed_count}/{num_images}: {content_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {content_file}: {str(e)}\")\n",
    "    \n",
    "    return generated_forgeries\n",
    "\n",
    "def save_image(tensor, filename):\n",
    "    \"\"\"Save a tensor to image file with proper denormalization\"\"\"\n",
    "    unloader = transforms.ToPILImage()\n",
    "    image = tensor.cpu().clone()\n",
    "    image = image.squeeze(0)\n",
    "    image = unloader(image)\n",
    "    image.save(filename)"
   ],
   "id": "84d4437a2bc8b6fd",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:21:15.365111Z",
     "start_time": "2025-03-26T01:21:15.361840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ArtBench10(CIFAR10):\n",
    "\n",
    "    base_folder = \"artbench-10-batches-py\"\n",
    "    url = \"https://artbench.eecs.berkeley.edu/files/artbench-10-python.tar.gz\"\n",
    "    filename = \"artbench-10-python.tar.gz\"\n",
    "    tgz_md5 = \"9df1e998ee026aae36ec60ca7b44960e\"\n",
    "    train_list = [\n",
    "        [\"data_batch_1\", \"c2e02a78dcea81fe6fead5f1540e542f\"],\n",
    "        [\"data_batch_2\", \"1102a4dcf41d4dd63e20c10691193448\"],\n",
    "        [\"data_batch_3\", \"177fc43579af15ecc80eb506953ec26f\"],\n",
    "        [\"data_batch_4\", \"566b2a02ccfbafa026fbb2bcec856ff6\"],\n",
    "        [\"data_batch_5\", \"faa6a572469542010a1c8a2a9a7bf436\"],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        [\"test_batch\", \"fa44530c8b8158467e00899609c19e52\"],\n",
    "    ]\n",
    "    meta = {\n",
    "        \"filename\": \"meta\",\n",
    "        \"key\": \"styles\",\n",
    "        \"md5\": \"5bdcafa7398aa6b75d569baaec5cd4aa\",\n",
    "    }"
   ],
   "id": "6c306394953d8d90",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:22:29.292851Z",
     "start_time": "2025-03-26T01:21:15.857795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_forgeries(\n",
    "    num_images=5,\n",
    "    content_dir=\"./signature_dataset/full_org/\",\n",
    "    save_dir=\"./synthetic_forged/\",\n",
    "    style_weight=1e5,\n",
    "    num_steps=500\n",
    "):\n",
    "    # Initialize model and parameters\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    imsize = 128\n",
    "    \n",
    "    # Load VGG model\n",
    "    cnn = models.vgg19(pretrained=True).features.to(device).eval()\n",
    "    \n",
    "    # Normalization parameters\n",
    "    cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
    "    cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
    "    \n",
    "    # Load style dataset\n",
    "    style_dataset = ArtBench10(\n",
    "        root=\"artbench10-py\",\n",
    "        train=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize((imsize, imsize)),\n",
    "            transforms.ToTensor(),\n",
    "        ]),\n",
    "        download=False\n",
    "    )\n",
    "    \n",
    "    # Generate forgeries WITH NUM_IMAGES CONTROL\n",
    "    generated_forgeries = nst_signature_forgery(\n",
    "        content_dir, \n",
    "        style_dataset, \n",
    "        save_dir, \n",
    "        cnn, \n",
    "        cnn_normalization_mean, \n",
    "        cnn_normalization_std,\n",
    "        device,\n",
    "        num_steps=num_steps,\n",
    "        num_images=num_images,\n",
    "        style_weight=style_weight  # Pass explicitly\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nGenerated {len(generated_forgeries)}/{num_images} synthetic forgeries in {save_dir}\")\n",
    "    return generated_forgeries\n",
    "\n",
    "# Execute with controlled output\n",
    "generated_files = generate_forgeries(num_images=5)"
   ],
   "id": "4ec904aa683fd8a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1/5: original_10_1.png\n",
      "Generated 2/5: original_10_10.png\n",
      "Generated 3/5: original_10_11.png\n",
      "Generated 4/5: original_10_12.png\n",
      "Generated 5/5: original_10_13.png\n",
      "\n",
      "Generated 5/5 synthetic forgeries in ./synthetic_forged/\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:32:55.612415Z",
     "start_time": "2025-03-26T01:32:55.509349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_forgeries(\n",
    "    model_path=\"svm_signature_classifier.pkl\",\n",
    "    forged_dir=\"./synthetic_forged/\"\n",
    "):\n",
    "    # Load the trained classifier\n",
    "    clf = joblib.load(model_path)\n",
    "    \n",
    "    # Get list of generated forgeries\n",
    "    forged_files = [\n",
    "        os.path.join(forged_dir, f)\n",
    "        for f in os.listdir(forged_dir)\n",
    "        if f.lower().endswith((\"png\", \"jpg\", \"jpeg\"))\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for forgery_path in forged_files:\n",
    "        # Directly pass the file path to extract_features\n",
    "        synthetic_features = extract_features(forgery_path)\n",
    "\n",
    "        # If extract_features returned None (e.g., couldn't load), skip\n",
    "        if synthetic_features is None:\n",
    "            print(f\"Warning: Could not process {forgery_path}\")\n",
    "            continue\n",
    "\n",
    "        # Reshape for SVM\n",
    "        synthetic_features = synthetic_features.reshape(1, -1)\n",
    "\n",
    "        # Predict with SVM\n",
    "        prediction = clf.predict(synthetic_features)\n",
    "        probabilities = clf.predict_proba(synthetic_features)\n",
    "\n",
    "        # Save result\n",
    "        results.append({\n",
    "            \"file\": os.path.basename(forgery_path),\n",
    "            \"prediction\": prediction[0],\n",
    "            \"probabilities\": probabilities[0]\n",
    "        })\n",
    "    \n",
    "    # Print results\n",
    "    for res in results:\n",
    "        label_str = \"Forged\" if res['prediction'] == 0 else \"Real\"\n",
    "        real_prob, fake_prob = res['probabilities']\n",
    "        print(f\"\\n=== {res['file']} ===\")\n",
    "        print(f\"Prediction: {label_str}\")\n",
    "        print(f\"Probabilities: [Fake: {real_prob:.2f}, Real: {fake_prob:.2f}]\")\n",
    "    \n",
    "    return results\n",
    "evaluation_results = evaluate_forgeries()\n"
   ],
   "id": "5baa8497c3f4fba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== forged_original_10_1.png ===\n",
      "Prediction: Real\n",
      "Probabilities: [Fake: 0.00, Real: 1.00]\n",
      "\n",
      "=== forged_original_10_10.png ===\n",
      "Prediction: Real\n",
      "Probabilities: [Fake: 0.00, Real: 1.00]\n",
      "\n",
      "=== forged_original_10_11.png ===\n",
      "Prediction: Real\n",
      "Probabilities: [Fake: 0.01, Real: 0.99]\n",
      "\n",
      "=== forged_original_10_12.png ===\n",
      "Prediction: Real\n",
      "Probabilities: [Fake: 0.00, Real: 1.00]\n",
      "\n",
      "=== forged_original_10_13.png ===\n",
      "Prediction: Real\n",
      "Probabilities: [Fake: 0.00, Real: 1.00]\n",
      "\n",
      "=== forgeries_1_24.png ===\n",
      "Prediction: Forged\n",
      "Probabilities: [Fake: 1.00, Real: 0.00]\n",
      "\n",
      "=== original_1_1.png ===\n",
      "Prediction: Real\n",
      "Probabilities: [Fake: 0.00, Real: 1.00]\n"
     ]
    }
   ],
   "execution_count": 74
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
